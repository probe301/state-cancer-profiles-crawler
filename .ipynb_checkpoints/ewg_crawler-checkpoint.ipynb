{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EWG Tap Water Database Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T12:20:57.895571",
     "start_time": "2018-01-28T12:20:57.767160"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import asyncio\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "import sys\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import json\n",
    "from pprint import pprint\n",
    "import requests\n",
    "from pyquery import PyQuery as pq\n",
    "# from sein import log\n",
    "from itertools import compress\n",
    "from collections import OrderedDict\n",
    "\n",
    "def _start_or_end_with(text, pattern):\n",
    "  pattern = tuple(pattern)\n",
    "  return text.startswith(pattern) or text.endswith(pattern)\n",
    "\n",
    "\n",
    "\n",
    "def save_csv(headers, content, path):\n",
    "  with open(path, 'w', encoding='utf-8') as f:\n",
    "    f_csv = csv.writer(f, lineterminator='\\n')\n",
    "    f_csv.writerow(headers)\n",
    "    f_csv.writerows(content)\n",
    "  print('save csv done', path)\n",
    "  \n",
    "\n",
    "def load_csv(path, sample=10, only_title=False, include=(), exclude=()):\n",
    "  with open(path) as f:\n",
    "    titles = f.readline().strip().split(',')\n",
    "\n",
    "  if include:\n",
    "    column_compress = [_start_or_end_with(title, include) for title in titles]\n",
    "  else:\n",
    "    column_compress = [True] * len(titles)\n",
    "  if exclude:\n",
    "    column_compress = [not _start_or_end_with(title, exclude) and tb for title, tb in zip(titles, column_compress)]\n",
    "\n",
    "  if only_title:\n",
    "    return list(compress(titles, column_compress))\n",
    "\n",
    "  with open(path) as f:\n",
    "    lines = csv.reader(f)\n",
    "    next(lines)\n",
    "    result = []\n",
    "    for i, line in enumerate(lines, 1):\n",
    "      if sample and i > sample:\n",
    "        break\n",
    "      # result.append([_load_csv_value_convert(x) for x in compress(line, column_compress)])\n",
    "      result.append([x for x in compress(line, column_compress)])\n",
    "\n",
    "  return result\n",
    "\n",
    "\n",
    "def windows(iterable, length=2, overlap=0, yield_tail=False):\n",
    "  '''按照固定窗口大小切片list, 可以重叠\n",
    "  滑动array窗口,\n",
    "  每次提供length数目的元素,如果有overlap则重复之前的元素\n",
    "  yield_tail: 最后不足 length 的那部分元素是否也要 yield'''\n",
    "  import itertools\n",
    "  if length <= overlap:\n",
    "    raise AttributeError('overlap {} cannot larger than length {}'.format(overlap, length))\n",
    "  it = iter(iterable)\n",
    "  results = list(itertools.islice(it, length))\n",
    "  while len(results) == length:\n",
    "    yield results\n",
    "    results = results[length-overlap:]\n",
    "    results.extend(itertools.islice(it, length-overlap))\n",
    "  if results and yield_tail:\n",
    "    yield results\n",
    "    \n",
    "def make_code_list(path):\n",
    "    ret = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            if line.startswith('PWS ID') or line.startswith('pwsid') or line.strip() == '':\n",
    "                continue\n",
    "            else:\n",
    "                ret.append(line.split(',')[0])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-27T11:39:16.178141",
     "start_time": "2018-01-27T11:39:16.048324"
    },
    "code_folding": [
     3
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "  \n",
    "  \n",
    "def merge_all_pwsids(output_file):\n",
    "  filenames = '''epa_water_system_summary_01_[8].csv\n",
    "  epa_water_system_summary_02_[19].csv\n",
    "  epa_water_system_summary_03_[None].csv\n",
    "  epa_water_system_summary_04_[120].csv\n",
    "  epa_water_system_summary_05_[282].csv\n",
    "  epa_water_system_summary_06_[151].csv\n",
    "  epa_water_system_summary_07_[21].csv\n",
    "  epa_water_system_summary_08_[239].csv\n",
    "  epa_water_system_summary_09_[567].csv\n",
    "  epa_water_system_summary_10_[202].csv\n",
    "  epa_water_system_summary_AK_[3549].csv\n",
    "  epa_water_system_summary_AL_[1810].csv\n",
    "  epa_water_system_summary_AR_[4194].csv\n",
    "  epa_water_system_summary_AS_[273].csv\n",
    "  epa_water_system_summary_AZ_[3967].csv\n",
    "  epa_water_system_summary_CA_[18131].csv\n",
    "  epa_water_system_summary_CO_[4588].csv\n",
    "  epa_water_system_summary_CT_[11043].csv\n",
    "  epa_water_system_summary_DE_[1300].csv\n",
    "  epa_water_system_summary_FL_[19678].csv\n",
    "  epa_water_system_summary_GA_[5469].csv\n",
    "  epa_water_system_summary_GU_[18].csv\n",
    "  epa_water_system_summary_HI_[228].csv\n",
    "  epa_water_system_summary_IA_[5201].csv\n",
    "  epa_water_system_summary_ID_[4321].csv\n",
    "  epa_water_system_summary_IL_[26598].csv\n",
    "  epa_water_system_summary_IN_[9488].csv\n",
    "  epa_water_system_summary_KS_[1683].csv\n",
    "  epa_water_system_summary_KY_[2189].csv\n",
    "  epa_water_system_summary_LA_[5051].csv\n",
    "  epa_water_system_summary_MA_[3476].csv\n",
    "  epa_water_system_summary_MD_[7800].csv\n",
    "  epa_water_system_summary_ME_[6191].csv\n",
    "  epa_water_system_summary_MI_[25680].csv\n",
    "  epa_water_system_summary_MN_[20946].csv\n",
    "  epa_water_system_summary_MO_[5698].csv\n",
    "  epa_water_system_summary_MP_[203].csv\n",
    "  epa_water_system_summary_MS_[3172].csv\n",
    "  epa_water_system_summary_MT_[4581].csv\n",
    "  epa_water_system_summary_NC_[23139].csv\n",
    "  epa_water_system_summary_ND_[1591].csv\n",
    "  epa_water_system_summary_NE_[2805].csv\n",
    "  epa_water_system_summary_NH_[4003].csv\n",
    "  epa_water_system_summary_NJ_[14658].csv\n",
    "  epa_water_system_summary_NM_[2591].csv\n",
    "  epa_water_system_summary_NN_[250].csv\n",
    "  epa_water_system_summary_NV_[1364].csv\n",
    "  epa_water_system_summary_NY_[25918].csv\n",
    "  epa_water_system_summary_OH_[15903].csv\n",
    "  epa_water_system_summary_OK_[5603].csv\n",
    "  epa_water_system_summary_OR_[5802].csv\n",
    "  epa_water_system_summary_PA_[22436].csv\n",
    "  epa_water_system_summary_PR_[965].csv\n",
    "  epa_water_system_summary_RI_[1112].csv\n",
    "  epa_water_system_summary_SC_[5894].csv\n",
    "  epa_water_system_summary_SD_[1538].csv\n",
    "  epa_water_system_summary_TN_[4939].csv\n",
    "  epa_water_system_summary_TX_[15282].csv\n",
    "  epa_water_system_summary_UT_[2114].csv\n",
    "  epa_water_system_summary_VA_[8721].csv\n",
    "  epa_water_system_summary_VI_[986].csv\n",
    "  epa_water_system_summary_VT_[4286].csv\n",
    "  epa_water_system_summary_WA_[9465].csv\n",
    "  epa_water_system_summary_WI_[23678].csv\n",
    "  epa_water_system_summary_WV_[4337].csv\n",
    "  epa_water_system_summary_WY_[1859].csv'''\n",
    "  \n",
    "  with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(['pwsid', 'state', 'national', 'this_utility'])\n",
    "    for filename in filenames.splitlines():\n",
    "    # for filename in ['epa_water_system_summary_WI_[23678].csv']:\n",
    "      codes = make_code_list('./epa_water_system/' + filename.strip())\n",
    "      f_csv.writerows([(code, '', '', '') for code in codes])\n",
    "      \n",
    "# 收集所有的 pwsid 到指定文件\n",
    "# merge_all_pwsids('ewg_all_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T12:21:01.225985",
     "start_time": "2018-01-28T12:21:01.208785"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NoDataException(Exception):\n",
    "    pass\n",
    "\n",
    "  \n",
    "def fetch_page(url):\n",
    "    r = requests.get(url)\n",
    "    return r.content\n",
    "\n",
    "\n",
    "def parse_nitrate_content(content):\n",
    "    doc = pq(content)\n",
    "    for div in doc.find('div.slide-toggle'):\n",
    "      h3 = pq(div).find('p')\n",
    "      if h3.text().startswith('Nitrate, a fertilizer chemical,'):\n",
    "        nitrate_div = div\n",
    "        break\n",
    "    else:\n",
    "      raise NoDataException('Not found Nitrate block')\n",
    "\n",
    "    figure = pq(nitrate_div).find('figure.levels-compare-figure')\n",
    "\n",
    "    state = figure.find('.state-ppb-popup').text()\n",
    "    national = figure.find('.national-ppb-popup').text()\n",
    "    utility = figure.find('.this-utility-ppb-popup').text()\n",
    "\n",
    "    return state, national, utility\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T17:03:44.519125",
     "start_time": "2018-01-28T16:39:54.393406"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "async def fetch_ewg_page(session, code):\n",
    "    url_fmt = 'https://www.ewg.org/tapwater/system.php?pws={}'.format\n",
    "    url = url_fmt(code)\n",
    "    # print('async fetch_ewg_page {url}'.format(**locals()))\n",
    "    async with session.get(url) as resp:\n",
    "        body = await resp.read()\n",
    "        try:\n",
    "            data = parse_nitrate_content(body)\n",
    "            ret = [code] + list(data)\n",
    "            # print('done {url} {ret}'.format(**locals()))\n",
    "        except NoDataException:\n",
    "            ret = [code, 'nodata', 'nodata', 'nodata']\n",
    "            # print('fail {url} data not_found'.format(**locals()))\n",
    "        except UnicodeDecodeError:\n",
    "            ret = [code, '', '', '']\n",
    "            print('fail {url} unicode error'.format(**locals()))\n",
    "#         with open(output_file, 'a') as output:\n",
    "#             output.write('{},{},{},{},{}\\n'.format(code, ret[0], ret[1], ret[2], url))\n",
    "    return ret\n",
    "    \n",
    "\n",
    "  \n",
    "\n",
    "def update_work_file(work_file, content, batch_results, count, title):\n",
    "    for pwsid, state, national, utility in batch_results:\n",
    "        content[pwsid] = state, national, utility\n",
    "        if state == '':\n",
    "            pass  # leave for next loop fetch\n",
    "        elif state == 'nodata':\n",
    "            count['nodata'] += 1\n",
    "        else:\n",
    "            count['done'] += 1\n",
    "        count['task'] -= 1\n",
    "      \n",
    "    print('current count: task {task}, done {done}, nodata {nodata}'.format(**count))\n",
    "    save_csv(title, [[k, *v] for k, v in content.items()], work_file)\n",
    "    return \n",
    "  \n",
    "  \n",
    "def run_async_tasks(work_file, task_per_turn=10, sleep_interval=3):\n",
    "  \n",
    "    codes = []\n",
    "    count = {'task': 0, 'done': 0, 'nodata': 0}\n",
    "    \n",
    "    title = load_csv(work_file, only_title=True)\n",
    "    content = OrderedDict()\n",
    "\n",
    "    for line in load_csv(work_file, sample=None):\n",
    "        pwsid, state, national, utility = line\n",
    "        content[pwsid] = state, national, utility\n",
    "        \n",
    "        if state == '':\n",
    "            count['task'] += 1\n",
    "            codes.append(pwsid)\n",
    "        elif state == 'nodata':\n",
    "            count['nodata'] += 1\n",
    "            codes.append(pwsid)\n",
    "        else:\n",
    "            count['done'] += 1\n",
    "            \n",
    "            \n",
    "    total_count = count['task'] + count['nodata'] + count['done']\n",
    "    print('read work_file {work_file}, total {total_count}'.format(**locals()))\n",
    "    print('current count: task {task}, done {done}, nodata {nodata}'.format(**count))\n",
    "    # return\n",
    "    # print(content)\n",
    "    \n",
    "    \n",
    "    session = aiohttp.ClientSession()\n",
    "    loop = asyncio.get_event_loop()\n",
    "    \n",
    "    batch_results = []\n",
    "    for part in windows(codes, length=task_per_turn, yield_tail=True):\n",
    "        print('send new tasks: ' + ' '.join(part))\n",
    "        tasks = [fetch_ewg_page(session, code) for code in part]\n",
    "        turn_results = loop.run_until_complete(asyncio.gather(*tasks))\n",
    "        # print('gather ', results)\n",
    "        batch_results.extend(turn_results)\n",
    "        \n",
    "        if len(batch_results) >= 1000:\n",
    "            update_work_file(work_file, content, batch_results, count, title)\n",
    "            batch_results = []\n",
    "        time.sleep(sleep_interval)\n",
    "        \n",
    "    if len(batch_results) >= 1:  # 最后残余的 code part\n",
    "        update_work_file(work_file, content, batch_results, count, title)\n",
    "        batch_results = []\n",
    "        \n",
    "run_async_tasks(work_file='ewg_all_sample.csv', \n",
    "                task_per_turn=50, \n",
    "                sleep_interval=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T16:38:22.698854",
     "start_time": "2018-01-28T16:38:22.673681"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load_csv('NY_[25918].csv', sample=10, only_title=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T16:39:04.918184",
     "start_time": "2018-01-28T16:39:04.903668"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('NY_[25918].csv','w', encoding='utf-8') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(headers)\n",
    "    f_csv.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
